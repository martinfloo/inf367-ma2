{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile, assemble\n",
    "from qiskit_aer import QasmSimulator\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit.circuit import ParameterVector\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = datasets.load_iris()\n",
    "dff = datasets.load_iris()\n",
    "dff = pd.DataFrame(data=np.c_[dff['data'], dff['target']], columns=dff['feature_names'] + ['target'])\n",
    "df = pd.DataFrame(data=np.c_[df['data'], df['target']], columns=df['feature_names'] + ['target'])\n",
    "df_columns = df.columns.values[:-1] \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(target\n",
       " 2.0    35\n",
       " 0.0    35\n",
       " 1.0    35\n",
       " Name: count, dtype: int64,\n",
       " target\n",
       " 2.0    18\n",
       " 1.0    17\n",
       " 0.0    17\n",
       " Name: count, dtype: int64,\n",
       " target\n",
       " 0.0    18\n",
       " 1.0    18\n",
       " 2.0    17\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df[df_columns], df['target'], test_size=0.30, random_state=0, stratify=df['target'])\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_train, y_train, test_size=0.5, random_state=0, stratify=y_train)\n",
    "\n",
    "y_train.value_counts(), y_val.value_counts(), y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "101                5.8               2.7                5.1               1.9   \n",
       "142                5.8               2.7                5.1               1.9   \n",
       "\n",
       "     target  \n",
       "101     2.0  \n",
       "142     2.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff[dff.duplicated(keep=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "In this project we decided that we will use ``angle encoding`` because we don't have that many quibits to work with. Since angle enncoding needs the data to be on a scale between $[0, 2\\pi]$, we will scale the data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom transformers for the pipeline\n",
    "class RemoveDuplicates(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        df = pd.DataFrame(X)\n",
    "        df = df.drop_duplicates()\n",
    "        return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 2*np.pi))\n",
    "remove_duplicates = RemoveDuplicates()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('remove_duplicates', remove_duplicates)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pipe.fit_transform(x_train)\n",
    "x_val = pipe.transform(x_val)\n",
    "x_test = pipe.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# choosing a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisQNN:\n",
    "    def __init__(self, n_qubits, n_layers):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        self.n_params = n_qubits * n_layers\n",
    "        self.params = ParameterVector('θ', self.n_params)\n",
    "    \n",
    "    def angle_encoding(self, qc, input_features):\n",
    "        number_of_qubits = qc.num_qubits\n",
    "        for qubit in range(number_of_qubits):\n",
    "            qc.rx(input_features[qubit], qubit)\n",
    "        qc.barrier()\n",
    "        return qc\n",
    "\n",
    "    def add_variational_layer_real_amplitude(self, qc, layer_idx):\n",
    "        param_offset = layer_idx * self.n_qubits\n",
    "        for i in range(self.n_qubits):\n",
    "            qc.ry(self.params[param_offset + i], i)\n",
    "        \n",
    "        qc.barrier()\n",
    "        \n",
    "        for i in range(self.n_qubits - 1):\n",
    "            qc.cx(i, i+1)\n",
    "            \n",
    "        if layer_idx < self.n_layers - 1:\n",
    "            qc.barrier()\n",
    "            \n",
    "        return qc\n",
    "\n",
    "    def create_circuit(self, input_features, variational_params=None):\n",
    "        qc = QuantumCircuit(self.n_qubits)\n",
    "        \n",
    "        self.angle_encoding(qc, input_features)\n",
    "        \n",
    "        for layer in range(self.n_layers):\n",
    "            self.add_variational_layer_real_amplitude(qc, layer)\n",
    "        \n",
    "        return qc\n",
    "    \n",
    "    def _get_parameter_count(self):\n",
    "        return self.n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiClassCrossEntropy(prediction, label):\n",
    "    \n",
    "    epsilon = 1e-15\n",
    "    prediction = np.clip(prediction, epsilon, 1 - epsilon)\n",
    "\n",
    "    return -np.sum(label * np.log(prediction))\n",
    "\n",
    "def split_into_batches(data, batch_size):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i+batch_size]\n",
    "\n",
    "def finiteDifference(lossFunction, params, paramIndex, epsilon, *args):\n",
    "    forward = np.array(params, copy=True)\n",
    "    backward = np.array(params, copy=True)\n",
    "    forward[paramIndex] += epsilon\n",
    "    backward[paramIndex] -= epsilon\n",
    "    forward_loss = lossFunction(forward, *args)\n",
    "    backward_loss = lossFunction(backward, *args)\n",
    "    gradient = (forward_loss - backward_loss) / (2 * epsilon)\n",
    "    return gradient\n",
    "\n",
    "def execute_circuits(quantum_circuits, backend, shots=1000):\n",
    "    for qc in quantum_circuits:\n",
    "        qc.measure_all()\n",
    "    transpiled_qcs = transpile(quantum_circuits, backend)\n",
    "    job = backend.run(transpiled_qcs, shots=shots)\n",
    "    return job.result()\n",
    "\n",
    "def updateParam(param, gradient, learningRate):\n",
    "    return param - learningRate * gradient\n",
    "\n",
    "def decoding(result, circuit, shots): \n",
    "    counts = result.get_counts(circuit) # counts from the execution of the circuit\n",
    "    probabilities = np.zeros(3) # array to store the probabilities of the classes\n",
    "    \n",
    "    for bitstring, count in counts.items():\n",
    "        classIndex = int(bitstring, 2) % 3 # convert bitstring to integer 0, 1 or 2\n",
    "        probabilities[classIndex] += count / shots # add the probability of the class\n",
    "    \n",
    "    probabilities /= np.sum(probabilities) # Ensuring normalization\n",
    "    return probabilities\n",
    "\n",
    "def produce_params(params, n_layers, n_qubits):\n",
    "    return np.random.uniform(0, 2*np.pi - 0.001, n_layers * n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m gradients \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(qnn\u001b[38;5;241m.\u001b[39mn_params):\n\u001b[0;32m---> 19\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m \u001b[43mfiniteDifference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmultiClassCrossEntropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariational_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     gradients\u001b[38;5;241m.\u001b[39mappend(gradient)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mold params\u001b[39m\u001b[38;5;124m\"\u001b[39m, variational_params)\n",
      "Cell \u001b[0;32mIn[114], line 17\u001b[0m, in \u001b[0;36mfiniteDifference\u001b[0;34m(lossFunction, params, paramIndex, epsilon, *args)\u001b[0m\n\u001b[1;32m     15\u001b[0m forward[paramIndex] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m epsilon\n\u001b[1;32m     16\u001b[0m backward[paramIndex] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m epsilon\n\u001b[0;32m---> 17\u001b[0m forward_loss \u001b[38;5;241m=\u001b[39m \u001b[43mlossFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m backward_loss \u001b[38;5;241m=\u001b[39m lossFunction(backward, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     19\u001b[0m gradient \u001b[38;5;241m=\u001b[39m (forward_loss \u001b[38;5;241m-\u001b[39m backward_loss) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m epsilon)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "qnn = IrisQNN(n_qubits=4, n_layers=2)\n",
    "epochs = 2\n",
    "\n",
    "x_train_sub = x_train[:1]\n",
    "backend = QasmSimulator()\n",
    "for epoch in range(epochs):\n",
    "    for batch in split_into_batches(x_train_sub, batch_size=1):\n",
    "        for feature in batch:\n",
    "            variational_params = produce_params(qnn.params, qnn.n_layers, qnn.n_qubits)\n",
    "            qc = qnn.create_circuit(feature)\n",
    "            qc = qc.assign_parameters({qnn.params: variational_params})\n",
    "            result = execute_circuits([qc], backend)\n",
    "            probabilities = decoding(result, qc, shots=1000)\n",
    "            label = np.zeros(3)\n",
    "            label[int(y_train.iloc[0])] = 1\n",
    "            loss = multiClassCrossEntropy(probabilities, label)\n",
    "            gradients = []\n",
    "            for i in range(qnn.n_params):\n",
    "                gradient = finiteDifference(multiClassCrossEntropy(probabilities, label), variational_params, i, 1e-2, label)\n",
    "                gradients.append(gradient)\n",
    "            print(\"old params\", variational_params)\n",
    "            for i in range(qnn.n_params):\n",
    "                variational_params[i] = updateParam(variational_params[i], gradients[i], 0.1)\n",
    "            print(\"new params\", variational_params)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Implent funciton for initialising the weights\n",
    "#TODO Implement funciton for creating circuits for all the training data\n",
    "#TODO implement function for calculating the cost function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf367",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
